## Importance-weigted Adversarial Domain Adaptation for Sound Source Tracking

This repository provides implementations of the paper "Importance-weigted Adversarial Domain Adaptation for Sound Source Tracking"

****The code includes:****

Training on simulated multi-channel audio (run_crnn.py)

Domain adaptation training using real recordings (run_crnn_DA.py)

Evaluation on real datasets (run_evaluation.py)

Configurable hyperparameters via params_config.py

## ğŸ“‚ Repository Structure

```bash 
.
â”œâ”€â”€ params_config.py       # Argument parser for all training/evaluation scripts
â”œâ”€â”€ run_crnn.py            # Training script on simulated data
â”œâ”€â”€ run_crnn_DA.py         # Domain adaptation training script
â”œâ”€â”€ run_evaluation.py      # Evaluation script on real recordings
â”œâ”€â”€ datasets/              # Dataset loaders (LibriSpeech, RealMAN, Noise, etc.)
â”œâ”€â”€ trainers/              # CRNN trainer classes (baseline + domain adaptation)
â”œâ”€â”€ models/                # CRNN model and domain discriminator Pytorch implementations
â”œâ”€â”€ logs/                  # Model bin files after training
â””â”€â”€ utils/                 # Utility functions (seeding, parameters, etc.)

```

## ğŸš€ Getting Started
### 1. Requirements

Python 3.8+ 

PyTorch â‰¥ 1.10 

[gpuRIR](https://github.com/DavidDiazGuerra/gpuRIR)

[webrtcvad](https://github.com/wiseman/py-webrtcvad) 

Numpy, matplotlib, scipy, soundfile, pandas and tqdm 


### 2. Dataset Setup

Target domain: [RealMAN dataset](https://github.com/Audio-WestlakeU/RealMAN)

The target domain data is separated into different scenes and it is organized as the follows (a bit different from the original data files in the link):

Dataset structure
```bash 
RealMAN_dataset
â”œâ”€â”€ train
  â”œâ”€â”€ dp_speech
    â”œâ”€â”€ OfficeRoom3
    â”œâ”€â”€ ...
    â”œâ”€â”€ ...
  â”œâ”€â”€ OfficeRoom3
  â”œâ”€â”€ ...
  â”œâ”€â”€ ...
  â”œâ”€â”€ noise
    â”œâ”€â”€ OfficeRoom3
    â”œâ”€â”€ ...
  â”œâ”€â”€ train_moving_source_location.csv
â”œâ”€â”€ test 
â”œâ”€â”€ val
```

Source domain: [LibriSpeech](https://www.openslr.org/12) (train-clean-100, test-clean)

Noise data: [NoiseX-92](https://github.com/speechdnn/Noises) 


Before training, update dataset paths in params_config.py:

```bash 
--source_path_train   # LibriSpeech training data
--source_path_test    # LibriSpeech test data
--real_data_dir       # RealMAN root directory
--target_path_train/va/test       # CSV files for train/val/test metadata
```

## ğŸ‹ï¸ Training
****1. Train CRNN on Synthetic Data****

First train the model on source domain (synthetic data): 
```bash 
python run_crnn.py
```
To change the parameters, you can simply modify the parameters in params_config.py or call the following:
```bash 
python run_crnn_DA.py \
    --batch_size 16 \
    --lr 1e-4 \
```

****2. Domain Adaptation Training****

Then carry out the domain adversarial training using the following script, but need to specify the model checkpoint path, which is the checkpoint of the model trained with the source domain data.

```bash 
python run_crnn_DA.py --model_checkpoint_path logs/crnn_source.bin
```



